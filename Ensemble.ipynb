{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOslX7jEnT8/+Ji0Ab6LRdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonzwon/TIL_DL/blob/master/Ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# voting ensemble"
      ],
      "metadata": {
        "id": "C5ArYLFRcyjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "RsaGJa0McyGd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAdJDyoqcvQH"
      },
      "outputs": [],
      "source": [
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hard voting\n",
        "log_clf = LogisticRegression(solver='lbfgs', random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma='scale', random_state=42)\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='hard'\n",
        ")"
      ],
      "metadata": {
        "id": "Qrn5wKYfdcCC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfnbjATLep_2",
        "outputId": "bafdbbb9-7e47-4b1d-84bf-1edce72ae559"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(random_state=42))])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37DHuNgYe2pL",
        "outputId": "8e1d4a80-7d05-433c-9b32-a8871a1722e5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# soft voting\n",
        "log_clf = LogisticRegression(solver='lbfgs', random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "svm_clf = SVC(gamma='scale', probability=True, random_state=42)\n",
        "\n",
        "soft_voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
        "    voting='soft'\n",
        ")"
      ],
      "metadata": {
        "id": "CBXpJBw4fZdo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_voting_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v1zitthgbas",
        "outputId": "3d8c8be9-5fa4-486b-98b7-d5dba4d70269"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
              "                             ('rf', RandomForestClassifier(random_state=42)),\n",
              "                             ('svc', SVC(probability=True, random_state=42))],\n",
              "                 voting='soft')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for clf in (log_clf, rnd_clf, svm_clf, soft_voting_clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qXIhPL2gb-H",
        "outputId": "46ade349-542e-48a2-af06-9d1d3f106508"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bagging"
      ],
      "metadata": {
        "id": "5K19A74hj29u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단일 결정트리 vs 배깅"
      ],
      "metadata": {
        "id": "wy0Bt4YBj9T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "metadata": {
        "id": "SBKIEbOskWQd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train, y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "\n",
        "# Bagging\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
        "                            n_estimators=500,\n",
        "                            max_samples=100,\n",
        "                            bootstrap=True,\n",
        "                            random_state=42)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "y_pred_bag = bag_clf.predict(X_test)\n",
        "\n",
        "print('Decision Tree accuracy : ', accuracy_score(y_test, y_pred_tree))\n",
        "print('Bagging accuracy : ', accuracy_score(y_test, y_pred_bag))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URWnEMbDk30K",
        "outputId": "c2f5e53b-cec2-4e3b-f452-7d7f661c88cc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy :  0.856\n",
            "Bagging accuracy :  0.904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- oob 평가"
      ],
      "metadata": {
        "id": "xXSICobgos2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
        "                            n_estimators=500,\n",
        "                            oob_score=True,\n",
        "                            bootstrap=True,\n",
        "                            random_state=40)\n",
        "bag_clf.fit(X_train, y_train)\n",
        "print('oob_score : ',bag_clf.oob_score_)\n",
        "print('oob_decision_function : ', bag_clf.oob_decision_function_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbMSe_A8l5s-",
        "outputId": "73d786ea-070d-44cb-afc0-32d44d1b7a56"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "oob_score :  0.8986666666666666\n",
            "oob_decision_function :  [[0.32275132 0.67724868]\n",
            " [0.34117647 0.65882353]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.09497207 0.90502793]\n",
            " [0.31147541 0.68852459]\n",
            " [0.01754386 0.98245614]\n",
            " [0.97109827 0.02890173]\n",
            " [0.97765363 0.02234637]\n",
            " [0.74404762 0.25595238]\n",
            " [0.         1.        ]\n",
            " [0.7173913  0.2826087 ]\n",
            " [0.85026738 0.14973262]\n",
            " [0.97222222 0.02777778]\n",
            " [0.0625     0.9375    ]\n",
            " [0.         1.        ]\n",
            " [0.97837838 0.02162162]\n",
            " [0.94642857 0.05357143]\n",
            " [1.         0.        ]\n",
            " [0.01704545 0.98295455]\n",
            " [0.39473684 0.60526316]\n",
            " [0.88700565 0.11299435]\n",
            " [1.         0.        ]\n",
            " [0.97790055 0.02209945]\n",
            " [0.         1.        ]\n",
            " [0.99428571 0.00571429]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.62569832 0.37430168]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.13402062 0.86597938]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.38251366 0.61748634]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.27093596 0.72906404]\n",
            " [0.34146341 0.65853659]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.00531915 0.99468085]\n",
            " [0.98843931 0.01156069]\n",
            " [0.91428571 0.08571429]\n",
            " [0.97282609 0.02717391]\n",
            " [0.98019802 0.01980198]\n",
            " [0.         1.        ]\n",
            " [0.07361963 0.92638037]\n",
            " [0.98019802 0.01980198]\n",
            " [0.0052356  0.9947644 ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.97790055 0.02209945]\n",
            " [0.8        0.2       ]\n",
            " [0.42424242 0.57575758]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.66477273 0.33522727]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.86781609 0.13218391]\n",
            " [1.         0.        ]\n",
            " [0.56725146 0.43274854]\n",
            " [0.1576087  0.8423913 ]\n",
            " [0.66492147 0.33507853]\n",
            " [0.91709845 0.08290155]\n",
            " [0.         1.        ]\n",
            " [0.16759777 0.83240223]\n",
            " [0.87434555 0.12565445]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.995      0.005     ]\n",
            " [0.         1.        ]\n",
            " [0.07878788 0.92121212]\n",
            " [0.05418719 0.94581281]\n",
            " [0.29015544 0.70984456]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.83040936 0.16959064]\n",
            " [0.01092896 0.98907104]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.21465969 0.78534031]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.94660194 0.05339806]\n",
            " [0.77094972 0.22905028]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.16574586 0.83425414]\n",
            " [0.65306122 0.34693878]\n",
            " [0.         1.        ]\n",
            " [0.02564103 0.97435897]\n",
            " [0.50555556 0.49444444]\n",
            " [1.         0.        ]\n",
            " [0.03208556 0.96791444]\n",
            " [0.99435028 0.00564972]\n",
            " [0.23699422 0.76300578]\n",
            " [0.49509804 0.50490196]\n",
            " [0.9947644  0.0052356 ]\n",
            " [0.00555556 0.99444444]\n",
            " [0.98963731 0.01036269]\n",
            " [0.26153846 0.73846154]\n",
            " [0.92972973 0.07027027]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.80113636 0.19886364]\n",
            " [1.         0.        ]\n",
            " [0.0106383  0.9893617 ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.98181818 0.01818182]\n",
            " [1.         0.        ]\n",
            " [0.01036269 0.98963731]\n",
            " [0.97752809 0.02247191]\n",
            " [0.99453552 0.00546448]\n",
            " [0.01960784 0.98039216]\n",
            " [0.17857143 0.82142857]\n",
            " [0.98387097 0.01612903]\n",
            " [0.29533679 0.70466321]\n",
            " [0.98295455 0.01704545]\n",
            " [0.         1.        ]\n",
            " [0.00561798 0.99438202]\n",
            " [0.75690608 0.24309392]\n",
            " [0.38624339 0.61375661]\n",
            " [0.40625    0.59375   ]\n",
            " [0.87368421 0.12631579]\n",
            " [0.92462312 0.07537688]\n",
            " [0.05181347 0.94818653]\n",
            " [0.82802548 0.17197452]\n",
            " [0.01546392 0.98453608]\n",
            " [0.         1.        ]\n",
            " [0.02298851 0.97701149]\n",
            " [0.9726776  0.0273224 ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.01041667 0.98958333]\n",
            " [0.         1.        ]\n",
            " [0.03804348 0.96195652]\n",
            " [0.02040816 0.97959184]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.94915254 0.05084746]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.99462366 0.00537634]\n",
            " [0.         1.        ]\n",
            " [0.39378238 0.60621762]\n",
            " [0.33152174 0.66847826]\n",
            " [0.00609756 0.99390244]\n",
            " [0.         1.        ]\n",
            " [0.3172043  0.6827957 ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.00588235 0.99411765]\n",
            " [0.         1.        ]\n",
            " [0.98924731 0.01075269]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.62893082 0.37106918]\n",
            " [0.92344498 0.07655502]\n",
            " [0.         1.        ]\n",
            " [0.99526066 0.00473934]\n",
            " [1.         0.        ]\n",
            " [0.98888889 0.01111111]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.06989247 0.93010753]\n",
            " [1.         0.        ]\n",
            " [0.03608247 0.96391753]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.02185792 0.97814208]\n",
            " [1.         0.        ]\n",
            " [0.95808383 0.04191617]\n",
            " [0.78362573 0.21637427]\n",
            " [0.56650246 0.43349754]\n",
            " [0.         1.        ]\n",
            " [0.18023256 0.81976744]\n",
            " [1.         0.        ]\n",
            " [0.93121693 0.06878307]\n",
            " [0.97175141 0.02824859]\n",
            " [1.         0.        ]\n",
            " [0.00531915 0.99468085]\n",
            " [0.         1.        ]\n",
            " [0.43010753 0.56989247]\n",
            " [0.85858586 0.14141414]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.00558659 0.99441341]\n",
            " [0.         1.        ]\n",
            " [0.96923077 0.03076923]\n",
            " [0.         1.        ]\n",
            " [0.21649485 0.78350515]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.98477157 0.01522843]\n",
            " [0.8        0.2       ]\n",
            " [0.99441341 0.00558659]\n",
            " [0.         1.        ]\n",
            " [0.09497207 0.90502793]\n",
            " [0.99492386 0.00507614]\n",
            " [0.01714286 0.98285714]\n",
            " [0.         1.        ]\n",
            " [0.02747253 0.97252747]\n",
            " [1.         0.        ]\n",
            " [0.77005348 0.22994652]\n",
            " [0.         1.        ]\n",
            " [0.90229885 0.09770115]\n",
            " [0.98387097 0.01612903]\n",
            " [0.22222222 0.77777778]\n",
            " [0.20348837 0.79651163]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.20338983 0.79661017]\n",
            " [0.98181818 0.01818182]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.98969072 0.01030928]\n",
            " [0.         1.        ]\n",
            " [0.48663102 0.51336898]\n",
            " [1.         0.        ]\n",
            " [0.00529101 0.99470899]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.08379888 0.91620112]\n",
            " [0.12352941 0.87647059]\n",
            " [0.99415205 0.00584795]\n",
            " [0.03517588 0.96482412]\n",
            " [1.         0.        ]\n",
            " [0.39790576 0.60209424]\n",
            " [0.05434783 0.94565217]\n",
            " [0.53191489 0.46808511]\n",
            " [0.51898734 0.48101266]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.60869565 0.39130435]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.24157303 0.75842697]\n",
            " [0.81578947 0.18421053]\n",
            " [0.08717949 0.91282051]\n",
            " [0.99453552 0.00546448]\n",
            " [0.82142857 0.17857143]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [0.11904762 0.88095238]\n",
            " [0.04188482 0.95811518]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.89150943 0.10849057]\n",
            " [0.19230769 0.80769231]\n",
            " [0.95238095 0.04761905]\n",
            " [0.00515464 0.99484536]\n",
            " [0.59375    0.40625   ]\n",
            " [0.07692308 0.92307692]\n",
            " [0.99484536 0.00515464]\n",
            " [0.83684211 0.16315789]\n",
            " [0.         1.        ]\n",
            " [0.99484536 0.00515464]\n",
            " [0.95360825 0.04639175]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.26395939 0.73604061]\n",
            " [0.98461538 0.01538462]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.00574713 0.99425287]\n",
            " [0.85142857 0.14857143]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.75301205 0.24698795]\n",
            " [0.8969697  0.1030303 ]\n",
            " [1.         0.        ]\n",
            " [0.75555556 0.24444444]\n",
            " [0.48863636 0.51136364]\n",
            " [0.         1.        ]\n",
            " [0.92473118 0.07526882]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.87709497 0.12290503]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.74752475 0.25247525]\n",
            " [0.09146341 0.90853659]\n",
            " [0.42268041 0.57731959]\n",
            " [0.22395833 0.77604167]\n",
            " [0.         1.        ]\n",
            " [0.87046632 0.12953368]\n",
            " [0.78212291 0.21787709]\n",
            " [0.00507614 0.99492386]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.02884615 0.97115385]\n",
            " [0.96       0.04      ]\n",
            " [0.93478261 0.06521739]\n",
            " [1.         0.        ]\n",
            " [0.50731707 0.49268293]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.01604278 0.98395722]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.96987952 0.03012048]\n",
            " [0.         1.        ]\n",
            " [0.05172414 0.94827586]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.99494949 0.00505051]\n",
            " [0.01675978 0.98324022]\n",
            " [1.         0.        ]\n",
            " [0.14583333 0.85416667]\n",
            " [0.         1.        ]\n",
            " [0.00546448 0.99453552]\n",
            " [0.         1.        ]\n",
            " [0.41836735 0.58163265]\n",
            " [0.13095238 0.86904762]\n",
            " [0.22110553 0.77889447]\n",
            " [1.         0.        ]\n",
            " [0.97647059 0.02352941]\n",
            " [0.21195652 0.78804348]\n",
            " [0.98882682 0.01117318]\n",
            " [0.         1.        ]\n",
            " [0.         1.        ]\n",
            " [1.         0.        ]\n",
            " [0.96428571 0.03571429]\n",
            " [0.34554974 0.65445026]\n",
            " [0.98235294 0.01764706]\n",
            " [1.         0.        ]\n",
            " [0.         1.        ]\n",
            " [0.99465241 0.00534759]\n",
            " [0.         1.        ]\n",
            " [0.06043956 0.93956044]\n",
            " [0.98214286 0.01785714]\n",
            " [1.         0.        ]\n",
            " [0.03108808 0.96891192]\n",
            " [0.58854167 0.41145833]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bagging 1) RandomForest"
      ],
      "metadata": {
        "id": "WjOxyt9sy9hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)\n",
        "print(y_pred_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T0RBypWpMeQ",
        "outputId": "28a6d889-6f61-4c59-a72c-a1d7d0ffbf4f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1\n",
            " 0 0 1 1 0 0 0 0 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bag_rf_clf = BaggingClassifier(DecisionTreeClassifier(max_features='sqrt', max_leaf_nodes=16),\n",
        "                               n_estimators=500,\n",
        "                               random_state=42)\n",
        "bag_rf_clf.fit(X_train, y_train)\n",
        "y_pred_bag_rf = bag_rf_clf.predict(X_test)\n",
        "print(y_pred_bag_rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kousR5OpzcRw",
        "outputId": "980d1b56-6608-44d7-8f77-ffab43a38bd0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 1 1 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 0 0\n",
            " 1 1 1 1 1 0 0 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 1 1\n",
            " 0 0 1 1 0 0 0 0 1 1 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(y_pred_bag_rf == y_pred_rf)/len(y_pred_bag_rf)  # 예측 결과가 동일함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHuzY-Fj0LyH",
        "outputId": "7946cbb4-dab4-4e1e-b6bd-400c6739d075"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d0RneUf50Y2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}